<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-10-17 Sun 15:38 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Reinforcement Learning Study</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Holy frege" />
<meta name="description" content="Org-HTML export made simple."
 />
<meta name="keywords" content="org-mode, export, html, theme, style, css, js, bigblow" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">Reinforcement Learning Study</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org83e66cf">1. Study의 시작</a>
<ul>
<li><a href="#org87ae56f">1.1. 좋은 자료들</a></li>
</ul>
</li>
<li><a href="#orgf1468f9">2. What is Reinforcement  Learning?</a>
<ul>
<li><a href="#org458e449">2.1. Reinforcement Learning</a></li>
<li><a href="#org98d6e1f">2.2. Learning?</a></li>
<li><a href="#org775941f">2.3. Reinforcement?</a></li>
<li><a href="#org027fbe8">2.4. Reinforcement + Learning</a></li>
<li><a href="#org7800dea">2.5. shutton교수의 생각</a></li>
</ul>
</li>
<li><a href="#org0921530">3. Reinforment Learning 용어들</a></li>
<li><a href="#org1a85b97">4. Learning에 대해서</a></li>
</ul>
</div>
</div>

<div id="outline-container-org83e66cf" class="outline-2">
<h2 id="org83e66cf"><span class="section-number-2">1</span> Study의 시작</h2>
<div class="outline-text-2" id="text-1">
<div class="note" id="org7a144bb">
<p>

</p>

<p>
A.I의 많은 논문들은 나같은 일반인이 이해하기 어려운 용어와 수식으로 가득차 있다. 내게 있어, A.I가  피부로 와닿지 못하는 큰 이유는, 나의 기초적 소양 부족이 첫번째 이유이고, 두번째로 추상적인 내용을 구체적 사례나 일상언어, 혹은 코딩으로 녹여내지 못하는데 있다고 본다. 스터디를 통해서 논문이나 책의 내용을 나만의 해석으로 이해하고 녹여내고 싶다. 그래서 내가 하는 얘기는 정석이 아니다. 다른 의견이 있을 수 있고 틀린 내용일 수 있다.
</p>

</div>
</div>

<div id="outline-container-org87ae56f" class="outline-3">
<h3 id="org87ae56f"><span class="section-number-3">1.1</span> 좋은 자료들</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>동영상</li>
</ul>
<div class="note" id="org616ba5d">
<p>
<a href="https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag">혁펜하임</a>, 
</p>

</div>
<ul class="org-ul">
<li>책, 논문</li>
</ul>
<div class="note" id="orgf269020">
<p>

</p>

</div>
<ul class="org-ul">
<li><p>
website
</p>
<div class="note" id="orga6c2b6e">
<p>
<a href="https://dnddnjs.gitbooks.io/rl/content/">RL Korea</a>,   
</p>

</div></li>
<li><p>
기타
</p>
<div class="note" id="orgebe323d">
<ul class="org-ul">
<li>unity 공부할 필요 있음.</li>
</ul>

</div></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf1468f9" class="outline-2">
<h2 id="orgf1468f9"><span class="section-number-2">2</span> What is Reinforcement  Learning?</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org458e449" class="outline-3">
<h3 id="org458e449"><span class="section-number-3">2.1</span> Reinforcement Learning</h3>
<div class="outline-text-3" id="text-2-1">
<div class="note" id="org088062e">
<p>

</p>

<ul class="org-ul">
<li>A.I의 한 분야.</li>
</ul>


<ul class="org-ul">
<li><b>A.I (Artificial Intelligence)?</b>
brain? IQ?
<i>Artificial intelligence is the simulation of human intelligence processes by machines.</i></li>
</ul>


<ul class="org-ul">
<li><b>Artificial is like simulation but what is intelligence?</b>
thinking? knowledge? know? cognition? what?
ex) <i>unintelligent: someone has used a lit match to see if there is any gas in a car’s gas tank.</i> 휘발유는  불에 탄다. 휘발유에 불을 붙이면 불이탄다는 knowledge를 몰라서 unintelligent한게 아니다. knowledge를  어떻게 활용 하느냐에 따라서 intelligent한지 unintelligent한지 알 수 있다. 이것이 intellingence의 의미가 아닐까?</li>
</ul>

</div>
<div class="important" id="orgc273435">
<ul class="org-ul">
<li><b>AI의 핵심은 intelligence behavior인거 같다.  knowledge나 deductive reasoning을 통한 behavior(action)는 일반적이지만, 특정 상황에서 intelligence하지 않다. 이와는 다르게  model(learning)을 통한 behavior는  intelligence할 수 있다. ex) 칼은 사람을 벨수 있다. 칼을 든 사람은 위험하다. 그래서 칼을 든 사람 가까이에 가면 안된다. 이런 deductive한 reasoning과 knowledge로 가지 않는 action을 취하는 것은 intelligence하지 않다. 칼을 든사람이 주방이란곳에 있다면, 요리사일 확률이 높다. 여기서 칼을 든 요리사로 가는 action은 intelligence한 것이다. 어떻게 보면 context-awareness와도 연관이 있는듯 하다.</b></li>
</ul>

</div>
</div>
</div>

<div id="outline-container-org98d6e1f" class="outline-3">
<h3 id="org98d6e1f"><span class="section-number-3">2.2</span> Learning?</h3>
<div class="outline-text-3" id="text-2-2">
<div class="note" id="orgd1bb877">
<p>

</p>

<ul class="org-ul">
<li><i>Learning in A.I is to make model through Inductive reasoning process.</i>
사례(data)로 법칙?을 만드는것.
deductive reasoning 방식과 다름. 작은 법칙을 조합해서 새로운 법칙을 만드는 것.</li>
</ul>


<ul class="org-ul">
<li><b>model?</b> Learning으로 통해서 만들어진 법칙, like inductive reasoning, deductive reasoning은 아니다.</li>
</ul>

</div>
</div>
</div>

<div id="outline-container-org775941f" class="outline-3">
<h3 id="org775941f"><span class="section-number-3">2.3</span> Reinforcement?</h3>
<div class="outline-text-3" id="text-2-3">
<div class="note" id="org44a0a8c">
<p>
Reinforcement란 용어를 Skinner의 이론에서 나왔다는 말이 많다. pavlov, thondike, skinner 중 skinner는 reward에 따른 생쥐연구로 더 비슷하긴 하다.(지렛대,먹이). 그런데 초창기의 연구인  pavlov도 읽어볼만 하다.
</p>

<p>
<i>The term reinforcement was introduced by Pavlov in 1903 to describe the strengthening of the association between an unconditioned and a conditioned stimulus that results when the two are presented together. -<a href="http://www.scholarpedia.org/article/Reinforcement#:~:text=The%20term%20reinforcement%20was%20introduced,the%20two%20are%20presented%20together.&amp;text=The%20term%20reinforcement%20is%20currently,learning%20than%20to%20stimulus%20learning.">참고</a></i>
</p>


<ul class="org-ul">
<li>강화: 개의 행동이 반복된 학습으로 조정될 수 있다.
UC: food, R: agent인 개가 침을 흘린다.
C: 종소리, =&gt;R:침을 흘린다.
=&gt; 종소리를 울려도 개가 침을 흘린다. 반복된 학습후, 종소리를 듣고 개는 침을 흘린다.</li>
</ul>

</div>
</div>
</div>

<div id="outline-container-org027fbe8" class="outline-3">
<h3 id="org027fbe8"><span class="section-number-3">2.4</span> Reinforcement + Learning</h3>
<div class="outline-text-3" id="text-2-4">
<div class="note" id="orga257ab8">
<p>
두개의 용어를 합쳐서 생각하면 어렴풋이, 어떤 특정한 대상이 있고, 이 대상은 나름대로의 행동이 있고, 이 행동이라는 것은 learning으로 만들어질 수 있다는 생각이 든다. 즉 개가 되었던 사람이 되었던 로봇이 되었던, action을 할수 있는 존재에 관한 학문이라는 것은 확실해 보인다. 그리고 그 존재의 action은 학습을 통해서 바뀔수 있다는 것을 말할려는 것 같다. Reinforcement Learning에서는 agent, action과 같은 용어를 그대로 사용한다. 
</p>

</div>
</div>
</div>

<div id="outline-container-org7800dea" class="outline-3">
<h3 id="org7800dea"><span class="section-number-3">2.5</span> shutton교수의 생각</h3>
<div class="outline-text-3" id="text-2-5">
<div class="note" id="org7aa6506">
<p>
<i>Reinforcement learning is defined not by characterizing learning methods, but by characterizing a learning problem.</i>
특이하게도 강화학습은 학습하는 "방식"으로 정의되는 것이 아니고 강화학습 "문제"인가로 정의되어 집니다. 그렇다면 어떤 문제가 강화학습 문제일까요? -<a href="https://dnddnjs.gitbooks.io/rl/content/what_is_reinforcement_learning.html">참조</a>
</p>

<p>
어떤식으로 학습하는지는 강화학습을 정의할 수 없다. 학습할 수 있는 문제 여부에 따라 강화학습을 정의한다.? 잘 모르겠음. 그냥 드는 생각은 모든 문제에 강화학습이 적용될 수 있다고 생각이 든다.
</p>

</div>
</div>
</div>
</div>
<div id="outline-container-org0921530" class="outline-2">
<h2 id="org0921530"><span class="section-number-2">3</span> Reinforment Learning 용어들</h2>
<div class="outline-text-2" id="text-3">
<div class="note" id="orga48d6de">
<ul class="org-ul">
<li><b>try and error search</b>: 시행착오, 기본 원리</li>
<li><b>optimal control</b>:</li>
<li><b>Agent</b>: 없으면 안돼? behavior를 판단하는 주체.</li>
<li><b>Actions</b>: 없으면 안돼? 선택가능한 behaviors.</li>
<li><b>Environments</b>: 없으면 안돼? Deductive Reasoning이나 knowledge기반으로 behavior를 하는게 아니다. 특정 조건, 특정 환경에서,  intelligence behavior를 할 것이기 때문에 없으면 안된다.</li>
<li><b>Goal</b>:</li>
<li><b>Learning</b>: 수백 수천번의 episode를 실행해서 현재상태에서 goal에 이르는 정보를 찾는 과정.</li>
<li><b>state(status)</b>: 없으면 안돼? action이 없다면 상태도 없다.</li>
<li><b>episode</b>: 시행착오끝에 goal에 가면 하나의 episode.</li>
<li><b>Exploitation</b>: episode를 통해서 얻은 정보를 이용.</li>
<li><b>Exploration</b>: 아무런 정보없이 try.</li>
<li><b>Reward</b>:</li>
<li><b>MDP</b>:</li>
<li><b>Monte Carlo</b>:</li>
<li><b>planning</b>:</li>
<li><b>policy</b>:</li>
</ul>

</div>
</div>
</div>

<div id="outline-container-org1a85b97" class="outline-2">
<h2 id="org1a85b97"><span class="section-number-2">4</span> Learning에 대해서</h2>
<div class="outline-text-2" id="text-4">
<div class="note" id="org1a877b0">
<p>
헨젤과 그레텔의 breadscrum 방식으로는 agent가 goal에 도달하는 정보를 얻기에 비용이 많이 든다. exploration을 하면서 모든 과정을 trace하는게 아니라, goal에 도달후 그 이전 상태만 기록한다.
</p>

</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Holy frege</p>
<p class="date">Created: 2021-10-17 Sun 15:38</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
